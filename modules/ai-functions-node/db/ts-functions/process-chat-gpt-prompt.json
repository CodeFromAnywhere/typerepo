{
  "createdAt": 1671105545458,
  "updatedAt": 1671105545458,
  "deletedAt": 0,
  "createdFirstAt": 1671105545458,
  "isApiExposed": true,
  "isExported": true,
  "groupAuthorization": {},
  "operationRelativeTypescriptFilePath": "src/processChatGptPrompt.ts",
  "commentsInside": [],
  "rawText": " async (config: {\n  contextContent?: string | null;\n  selectionContent?: string | null;\n  contextualPromptSlug?: string;\n  /**\n   * DESCRIPTION: These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format\n   */\n  customPromptContent?: string;\n  saveNewPromptWithName?: string | null;\n  isHeadless?: boolean;\n  prompt_projectRelativePath?: string;\n  thread?: string;\n  /**\n   * If true, it'll just validate if this will be executed, it won't return the actual result but will execute the result in the background\n   */\n  isDeferred?: boolean;\n}): Promise<ProcessPromptFunctionResult> => {\n  const {\n    contextContent,\n    contextualPromptSlug,\n    customPromptContent,\n    saveNewPromptWithName,\n    prompt_projectRelativePath,\n    selectionContent,\n    isHeadless,\n    isDeferred,\n    thread,\n  } = config;\n\n  const projectRoot = getProjectRoot();\n  if (!projectRoot) return { isSuccessful: false, message: \"no projectroot\" };\n  const prompt_absolutePath = prompt_projectRelativePath\n    ? path.join(projectRoot, prompt_projectRelativePath)\n    : undefined;\n\n  const exists = prompt_absolutePath\n    ? fs.existsSync(prompt_absolutePath)\n    : undefined;\n\n  if (prompt_absolutePath && !exists) {\n    return {\n      isSuccessful: false,\n      message: `You gave a path that doesn't exist:${prompt_absolutePath}`,\n    };\n  }\n\n  const contextualPrompt = await getContextualPrompt(\n    contextualPromptSlug,\n    customPromptContent,\n    saveNewPromptWithName || null\n  );\n  if (!contextualPrompt) {\n    return {\n      isSuccessful: false,\n      message: \"Couldn't create or find a contextual prompt\",\n    };\n  }\n\n  /**\nensure `%context, %selection, %comment` are all valid variables in the prompt\n\nTODO: replace this with javascrpit-alike syntax (e.g. ${variableName})\n*/\n\n  const finalPrompt = contextualPrompt.promptContent\n    .replaceAll(\"%context\", contextContent || \"\")\n    .replaceAll(\"%selection\", selectionContent || \"\");\n\n  /**\n   * Disable this for now\n   */\n  const useChatGpt = false;\n\n  /**\nsend it to the processor, which sends response back after a few seconds\n*/\n  const promiseResult = controlChatGptWrapper(\n    finalPrompt,\n    isHeadless,\n    thread,\n    \"puppeteer\"\n  ).then(async (promptFunctionResult) => {\n    const newResult: Storing<ContextualPromptResult> = {\n      createdAt: Date.now(),\n      updatedAt: Date.now(),\n      createdFirstAt: Date.now(),\n      deletedAt: 0,\n      id: generateId(),\n      resultAssets: [],\n      resultText: promptFunctionResult.result?.text,\n      prompt: finalPrompt,\n      selectionString: selectionContent || undefined,\n      prompt_projectRelativePath,\n      thread: promptFunctionResult.result?.thread,\n      contextualPromptSlug: contextualPrompt.slug,\n      isFake: !useChatGpt,\n    };\n\n    // NB: insert into .index\n\n    const contextualPromptResultsJsonPath =\n      await getContextualPromptResultJsonFilePath(prompt_projectRelativePath);\n\n    const upsertResult = contextualPromptResultsJsonPath\n      ? await alterJsonMultiple(\n          {\n            absolutePath: contextualPromptResultsJsonPath,\n            modelName: \"ContextualPromptResult\",\n            operationName: null,\n            projectRelativePath: makeRelative(\n              contextualPromptResultsJsonPath,\n              projectRoot\n            ),\n          },\n          (storedData) => {\n            const result = upsert(storedData, newResult);\n            return result;\n          }\n        )\n      : undefined;\n\n    return {\n      upsertResult,\n      promptFunctionResult: promptFunctionResult?.result,\n    };\n  });\n\n  const processPromptFunctionResult = isDeferred\n    ? undefined\n    : await promiseResult;\n\n  const result =\n    isDeferred || !processPromptFunctionResult\n      ? undefined\n      : processPromptFunctionResult.promptFunctionResult;\n\n  return {\n    isSuccessful: isDeferred ? true : !!result?.text || false,\n    message: isDeferred\n      ? \"Prompt is now being executed\"\n      : processPromptFunctionResult?.upsertResult?.message || \"WentWrong\",\n    result,\n  };\n}",
  "name": "processChatGptPrompt",
  "slug": "process-chat-gpt-prompt",
  "parameters": [
    {
      "name": "config",
      "schema": {
        "type": "object",
        "properties": {
          "contextContent": {
            "type": [
              "string",
              "null"
            ]
          },
          "selectionContent": {
            "type": [
              "string",
              "null"
            ]
          },
          "contextualPromptSlug": {
            "type": "string"
          },
          "customPromptContent": {
            "type": "string",
            "description": "DESCRIPTION: These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format"
          },
          "saveNewPromptWithName": {
            "type": [
              "string",
              "null"
            ]
          },
          "isHeadless": {
            "type": "boolean"
          },
          "prompt_projectRelativePath": {
            "type": "string"
          },
          "thread": {
            "type": "string"
          },
          "isDeferred": {
            "type": "boolean",
            "description": "If true, it'll just validate if this will be executed, it won't return the actual result but will execute the result in the background"
          }
        },
        "additionalProperties": false
      },
      "simplifiedSchema": {
        "properties": [
          {
            "name": "contextContent",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "selectionContent",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "contextualPromptSlug",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "customPromptContent",
            "required": false,
            "schema": {
              "fullComment": "DESCRIPTION: These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format",
              "description": "These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format",
              "type": "string"
            }
          },
          {
            "name": "saveNewPromptWithName",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "isHeadless",
            "required": false,
            "schema": {
              "type": "boolean"
            }
          },
          {
            "name": "prompt_projectRelativePath",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "thread",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "isDeferred",
            "required": false,
            "schema": {
              "fullComment": "If true, it'll just validate if this will be executed, it won't return the actual result but will execute the result in the background",
              "type": "boolean"
            }
          }
        ],
        "type": "object"
      },
      "required": true
    }
  ],
  "description": "",
  "returnType": {
    "rawType": "Promise<import(\"/Users/king/King/operations/tools/ai/ai-types/build/ProcessPromptFunctionResult\").ProcessPromptFunctionResult>",
    "typeCoverage": 0,
    "isArray": false,
    "isEnum": false,
    "isObject": false,
    "isPrimitive": false,
    "isEnumLiteral": false
  },
  "maxIndentationDepth": 7,
  "size": {
    "characters": 4140,
    "lines": 144,
    "bytes": 4140,
    "bytesPerCharacter": 1,
    "charactersPerLine": 29,
    "linesPerFile": 144,
    "numberOfFiles": 1
  },
  "id": "yuuavjpxylzunmpacnqrxguq"
}