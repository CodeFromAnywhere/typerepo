{
  "createdAt": 1673524364475,
  "updatedAt": 1673524364475,
  "deletedAt": 0,
  "createdFirstAt": 1673524364475,
  "isApiExposed": false,
  "isExported": true,
  "operationRelativeTypescriptFilePath": "src/processChatGptPrompt.ts",
  "commentsInside": [],
  "rawText": " async (\n  config: ProcessPromptProps\n): Promise<ProcessPromptFunctionResult> => {\n  const {\n    //context\n    contextContent,\n    prompt_projectRelativePath,\n    selectionContent,\n    //existing or new\n    contextualPromptSlug,\n    customPromptContent,\n    saveNewPromptWithName,\n    // config\n    isHeadless,\n    isDeferred,\n    thread,\n  } = config;\n\n  const extension = prompt_projectRelativePath\n    ? path.parse(prompt_projectRelativePath).ext.slice(1)\n    : undefined;\n\n  const contextType = fileTypePerExtension[\n    extension as keyof typeof fileTypePerExtension\n  ] as FileType | undefined;\n\n  const projectRoot = getProjectRoot();\n  if (!projectRoot) return { isSuccessful: false, message: \"no projectroot\" };\n  const prompt_absolutePath = prompt_projectRelativePath\n    ? path.join(projectRoot, prompt_projectRelativePath)\n    : undefined;\n\n  const exists = prompt_absolutePath\n    ? fs.existsSync(prompt_absolutePath)\n    : undefined;\n\n  if (prompt_absolutePath && !exists) {\n    return {\n      isSuccessful: false,\n      message: `You gave a path that doesn't exist:${prompt_absolutePath}`,\n    };\n  }\n\n  const contextualPrompt = await getContextualPrompt(\n    contextualPromptSlug,\n    customPromptContent,\n    saveNewPromptWithName || null,\n    contextType\n  );\n  if (!contextualPrompt) {\n    return {\n      isSuccessful: false,\n      message: \"Couldn't create or find a contextual prompt\",\n    };\n  }\n\n  /**\nensure `%context, %selection, %comment` are all valid variables in the prompt\n\nTODO: replace this with javascrpit-alike syntax (e.g. ${variableName})\n*/\n\n  const finalPrompt = { ...contextualPrompt }.promptContent\n    .replaceAll(\"%context\", contextContent || \"\")\n    .replaceAll(\"%selection\", selectionContent || \"\")\n    .replaceAll(\"%any\", selectionContent || contextContent || \"\");\n\n  /**\n   * Disable this for now\n   */\n  const useChatGpt = true;\n\n  /**\nsend it to the processor, which sends response back after a few seconds\n*/\n  const promiseResult = controlChatGptWrapper(\n    finalPrompt,\n    isHeadless,\n    thread,\n    \"puppeteer\"\n  ).then(async (promptFunctionResult) => {\n    const newResult: Storing<ContextualPromptResult> = {\n      createdAt: Date.now(),\n      updatedAt: Date.now(),\n      createdFirstAt: Date.now(),\n      deletedAt: 0,\n      id: generateId(),\n      resultAssets: [],\n      resultText: promptFunctionResult.result?.text,\n      prompt: finalPrompt,\n      selectionString: selectionContent || undefined,\n      prompt_projectRelativePath,\n      thread: promptFunctionResult.result?.thread,\n      contextualPromptSlug: contextualPrompt.slug,\n      isFake: !useChatGpt,\n    };\n\n    // NB: insert into .index\n\n    const contextualPromptResultsJsonPath =\n      await getContextualPromptResultJsonFilePath(prompt_projectRelativePath);\n\n    const upsertResult = contextualPromptResultsJsonPath\n      ? await alterJsonMultiple(\n          {\n            absolutePath: contextualPromptResultsJsonPath,\n            modelName: \"ContextualPromptResult\",\n            operationName: null,\n            projectRelativePath: makeRelative(\n              contextualPromptResultsJsonPath,\n              projectRoot\n            ),\n          },\n          (storedData) => {\n            const result = upsert(storedData, newResult);\n            return result;\n          }\n        )\n      : undefined;\n\n    return {\n      upsertResult,\n      promptFunctionResult: promptFunctionResult?.result,\n    };\n  });\n\n  const processPromptFunctionResult = isDeferred\n    ? undefined\n    : await promiseResult;\n\n  const result =\n    isDeferred || !processPromptFunctionResult\n      ? undefined\n      : processPromptFunctionResult.promptFunctionResult;\n\n  return {\n    isSuccessful: isDeferred ? true : !!result?.text || false,\n    message: isDeferred\n      ? \"Prompt is now being executed\"\n      : processPromptFunctionResult?.upsertResult?.message || \"WentWrong\",\n    result,\n  };\n}",
  "name": "processChatGptPrompt",
  "slug": "process-chat-gpt-prompt",
  "parameters": [
    {
      "name": "config",
      "schema": {
        "$ref": "#/definitions/ProcessPromptProps"
      },
      "simplifiedSchema": {
        "fullComment": "",
        "properties": [
          {
            "name": "contextContent",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "selectionContent",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "contextualPromptSlug",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "anyContext",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "customPromptContent",
            "required": false,
            "schema": {
              "fullComment": "DESCRIPTION: These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format",
              "description": "These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format",
              "type": "string"
            }
          },
          {
            "name": "saveNewPromptWithName",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "isHeadless",
            "required": false,
            "schema": {
              "type": "boolean"
            }
          },
          {
            "name": "prompt_projectRelativePath",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "thread",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "isDeferred",
            "required": false,
            "schema": {
              "fullComment": "If true, it'll just validate if this will be executed, it won't return the actual result but will execute the result in the background",
              "type": "boolean"
            }
          }
        ],
        "type": "object"
      },
      "required": true
    }
  ],
  "description": "",
  "returnType": {
    "rawType": "Promise<import(\"/Users/clarity/os/operations/tools/ai/ai-types/build/ProcessPromptFunctionResult\").ProcessPromptFunctionResult>",
    "typeCoverage": 0,
    "isArray": false,
    "isEnum": false,
    "isObject": false,
    "isPrimitive": false,
    "isEnumLiteral": false
  },
  "maxIndentationDepth": 7,
  "size": {
    "characters": 3901,
    "lines": 143,
    "bytes": 3901,
    "bytesPerCharacter": 1,
    "charactersPerLine": 27,
    "linesPerFile": 143,
    "numberOfFiles": 1
  },
  "id": "jhuphyvxtdtoegjujiwygpki"
}