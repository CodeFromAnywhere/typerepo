{
  "createdAt": 1671105545885,
  "updatedAt": 1671105545885,
  "deletedAt": 0,
  "createdFirstAt": 1671105545885,
  "classification": "const",
  "comments": [],
  "isExported": true,
  "name": "processChatGptPrompt",
  "slug": "process-chat-gpt-prompt",
  "operationRelativeTypescriptFilePath": "src/processChatGptPrompt.ts",
  "type": {
    "rawType": "(config: { contextContent?: string | null | undefined; selectionContent?: string | null | undefined; contextualPromptSlug?: string | undefined; customPromptContent?: string | undefined; saveNewPromptWithName?: string | null | undefined; isHeadless?: boolean | undefined; prompt_projectRelativePath?: string | undefined; thread?: string | undefined; isDeferred?: boolean | undefined; }) => Promise<import(\"/Users/king/King/operations/tools/ai/ai-types/build/ProcessPromptFunctionResult\").ProcessPromptFunctionResult>",
    "typeDefinition": {
      "type": "object",
      "properties": {},
      "optional": false
    },
    "typeCoverage": 0,
    "isArray": false,
    "isEnum": false,
    "isObject": true,
    "isPrimitive": false,
    "isEnumLiteral": false,
    "simplifiedSchema": {
      "properties": [],
      "type": "object"
    }
  },
  "value": "async (config: {\n  contextContent?: string | null;\n  selectionContent?: string | null;\n  contextualPromptSlug?: string;\n  /**\n   * DESCRIPTION: These variables can be used: %context will be replaced by your context, %selection will be replaced by your selection. Provide a good prompt that combines that in a specific format\n   */\n  customPromptContent?: string;\n  saveNewPromptWithName?: string | null;\n  isHeadless?: boolean;\n  prompt_projectRelativePath?: string;\n  thread?: string;\n  /**\n   * If true, it'll just validate if this will be executed, it won't return the actual result but will execute the result in the background\n   */\n  isDeferred?: boolean;\n}): Promise<ProcessPromptFunctionResult> => {\n  const {\n    contextContent,\n    contextualPromptSlug,\n    customPromptContent,\n    saveNewPromptWithName,\n    prompt_projectRelativePath,\n    selectionContent,\n    isHeadless,\n    isDeferred,\n    thread,\n  } = config;\n\n  const projectRoot = getProjectRoot();\n  if (!projectRoot) return { isSuccessful: false, message: \"no projectroot\" };\n  const prompt_absolutePath = prompt_projectRelativePath\n    ? path.join(projectRoot, prompt_projectRelativePath)\n    : undefined;\n\n  const exists = prompt_absolutePath\n    ? fs.existsSync(prompt_absolutePath)\n    : undefined;\n\n  if (prompt_absolutePath && !exists) {\n    return {\n      isSuccessful: false,\n      message: `You gave a path that doesn't exist:${prompt_absolutePath}`,\n    };\n  }\n\n  const contextualPrompt = await getContextualPrompt(\n    contextualPromptSlug,\n    customPromptContent,\n    saveNewPromptWithName || null\n  );\n  if (!contextualPrompt) {\n    return {\n      isSuccessful: false,\n      message: \"Couldn't create or find a contextual prompt\",\n    };\n  }\n\n  /**\nensure `%context, %selection, %comment` are all valid variables in the prompt\n\nTODO: replace this with javascrpit-alike syntax (e.g. ${variableName})\n*/\n\n  const finalPrompt = contextualPrompt.promptContent\n    .replaceAll(\"%context\", contextContent || \"\")\n    .replaceAll(\"%selection\", selectionContent || \"\");\n\n  /**\n   * Disable this for now\n   */\n  const useChatGpt = false;\n\n  /**\nsend it to the processor, which sends response back after a few seconds\n*/\n  const promiseResult = controlChatGptWrapper(\n    finalPrompt,\n    isHeadless,\n    thread,\n    \"puppeteer\"\n  ).then(async (promptFunctionResult) => {\n    const newResult: Storing<ContextualPromptResult> = {\n      createdAt: Date.now(),\n      updatedAt: Date.now(),\n      createdFirstAt: Date.now(),\n      deletedAt: 0,\n      id: generateId(),\n      resultAssets: [],\n      resultText: promptFunctionResult.result?.text,\n      prompt: finalPrompt,\n      selectionString: selectionContent || undefined,\n      prompt_projectRelativePath,\n      thread: promptFunctionResult.result?.thread,\n      contextualPromptSlug: contextualPrompt.slug,\n      isFake: !useChatGpt,\n    };\n\n    // NB: insert into .index\n\n    const contextualPromptResultsJsonPath =\n      await getContextualPromptResultJsonFilePath(prompt_projectRelativePath);\n\n    const upsertResult = contextualPromptResultsJsonPath\n      ? await alterJsonMultiple(\n          {\n            absolutePath: contextualPromptResultsJsonPath,\n            modelName: \"ContextualPromptResult\",\n            operationName: null,\n            projectRelativePath: makeRelative(\n              contextualPromptResultsJsonPath,\n              projectRoot\n            ),\n          },\n          (storedData) => {\n            const result = upsert(storedData, newResult);\n            return result;\n          }\n        )\n      : undefined;\n\n    return {\n      upsertResult,\n      promptFunctionResult: promptFunctionResult?.result,\n    };\n  });\n\n  const processPromptFunctionResult = isDeferred\n    ? undefined\n    : await promiseResult;\n\n  const result =\n    isDeferred || !processPromptFunctionResult\n      ? undefined\n      : processPromptFunctionResult.promptFunctionResult;\n\n  return {\n    isSuccessful: isDeferred ? true : !!result?.text || false,\n    message: isDeferred\n      ? \"Prompt is now being executed\"\n      : processPromptFunctionResult?.upsertResult?.message || \"WentWrong\",\n    result,\n  };\n}",
  "description": "",
  "id": "bsmzhmqzoukbhkbjaiepvckp"
}